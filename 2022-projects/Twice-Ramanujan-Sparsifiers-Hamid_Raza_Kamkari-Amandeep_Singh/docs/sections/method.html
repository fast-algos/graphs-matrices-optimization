<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="en" xml:lang="en"><head>

<meta charset="utf-8">
<meta name="generator" content="quarto-1.2.280">

<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes">


<title>method</title>
<style>
code{white-space: pre-wrap;}
span.smallcaps{font-variant: small-caps;}
div.columns{display: flex; gap: min(4vw, 1.5em);}
div.column{flex: auto; overflow-x: auto;}
div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
ul.task-list{list-style: none;}
ul.task-list li input[type="checkbox"] {
  width: 0.8em;
  margin: 0 0.8em 0.2em -1.6em;
  vertical-align: middle;
}
pre > code.sourceCode { white-space: pre; position: relative; }
pre > code.sourceCode > span { display: inline-block; line-height: 1.25; }
pre > code.sourceCode > span:empty { height: 1.2em; }
.sourceCode { overflow: visible; }
code.sourceCode > span { color: inherit; text-decoration: inherit; }
div.sourceCode { margin: 1em 0; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
pre > code.sourceCode { white-space: pre-wrap; }
pre > code.sourceCode > span { text-indent: -5em; padding-left: 5em; }
}
pre.numberSource code
  { counter-reset: source-line 0; }
pre.numberSource code > span
  { position: relative; left: -4em; counter-increment: source-line; }
pre.numberSource code > span > a:first-child::before
  { content: counter(source-line);
    position: relative; left: -1em; text-align: right; vertical-align: baseline;
    border: none; display: inline-block;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
    color: #aaaaaa;
  }
pre.numberSource { margin-left: 3em; border-left: 1px solid #aaaaaa;  padding-left: 4px; }
div.sourceCode
  {   }
@media screen {
pre > code.sourceCode > span > a:first-child::before { text-decoration: underline; }
}
code span.al { color: #ff0000; font-weight: bold; } /* Alert */
code span.an { color: #60a0b0; font-weight: bold; font-style: italic; } /* Annotation */
code span.at { color: #7d9029; } /* Attribute */
code span.bn { color: #40a070; } /* BaseN */
code span.bu { color: #008000; } /* BuiltIn */
code span.cf { color: #007020; font-weight: bold; } /* ControlFlow */
code span.ch { color: #4070a0; } /* Char */
code span.cn { color: #880000; } /* Constant */
code span.co { color: #60a0b0; font-style: italic; } /* Comment */
code span.cv { color: #60a0b0; font-weight: bold; font-style: italic; } /* CommentVar */
code span.do { color: #ba2121; font-style: italic; } /* Documentation */
code span.dt { color: #902000; } /* DataType */
code span.dv { color: #40a070; } /* DecVal */
code span.er { color: #ff0000; font-weight: bold; } /* Error */
code span.ex { } /* Extension */
code span.fl { color: #40a070; } /* Float */
code span.fu { color: #06287e; } /* Function */
code span.im { color: #008000; font-weight: bold; } /* Import */
code span.in { color: #60a0b0; font-weight: bold; font-style: italic; } /* Information */
code span.kw { color: #007020; font-weight: bold; } /* Keyword */
code span.op { color: #666666; } /* Operator */
code span.ot { color: #007020; } /* Other */
code span.pp { color: #bc7a00; } /* Preprocessor */
code span.sc { color: #4070a0; } /* SpecialChar */
code span.ss { color: #bb6688; } /* SpecialString */
code span.st { color: #4070a0; } /* String */
code span.va { color: #19177c; } /* Variable */
code span.vs { color: #4070a0; } /* VerbatimString */
code span.wa { color: #60a0b0; font-weight: bold; font-style: italic; } /* Warning */
</style>


<script src="method_files/libs/clipboard/clipboard.min.js"></script>
<script src="method_files/libs/quarto-html/quarto.js"></script>
<script src="method_files/libs/quarto-html/popper.min.js"></script>
<script src="method_files/libs/quarto-html/tippy.umd.min.js"></script>
<script src="method_files/libs/quarto-html/anchor.min.js"></script>
<link href="method_files/libs/quarto-html/tippy.css" rel="stylesheet">
<link href="method_files/libs/quarto-html/quarto-syntax-highlighting.css" rel="stylesheet" id="quarto-text-highlighting-styles">
<script src="method_files/libs/bootstrap/bootstrap.min.js"></script>
<link href="method_files/libs/bootstrap/bootstrap-icons.css" rel="stylesheet">
<link href="method_files/libs/bootstrap/bootstrap.min.css" rel="stylesheet" id="quarto-bootstrap" data-mode="light">

  <script src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-chtml-full.js" type="text/javascript"></script>

</head>

<body class="fullcontent">

<div id="quarto-content" class="page-columns page-rows-contents page-layout-article">

<main class="content" id="quarto-document-content">



<p>We will now discuss the deterministic algorithm for approximating the matrix <span class="math inline">\(A\)</span>. The algorithm takes an iterative approach and follows <span class="math inline">\(N\)</span> iterations. At each iteration, it will pick a vector <span class="math inline">\(v_i\)</span> which corresponds to an edge and will add <span class="math inline">\(s_i v_i v_i^T\)</span> to the current accumulated matrix. After <span class="math inline">\(k\)</span> iterations it will give a good approximation for the matrix <span class="math inline">\(A\)</span>. But before we present the bulk of the algorithm, letâ€™s start by laying some groundwork and presenting some useful intuitions.</p>
<section id="geometric-interpretation" class="level3">
<h3 class="anchored" data-anchor-id="geometric-interpretation">Geometric interpretation</h3>
<p>Note that for any pair of matrices <span class="math inline">\(A\)</span> and <span class="math inline">\(B\)</span>, having the same null-space we have that <span class="math inline">\(A \succeq B \Longleftrightarrow I \succeq A^{+/2} B A^{+/2}\)</span>. Hence, <span class="math display">\[A \approx_\epsilon B \Longleftrightarrow \Pi \approx_\epsilon A^{+/2} B A^{+/2}\]</span> where <span class="math inline">\(\Pi = A^{+/2} A A^{+/2}\)</span> is the identity in the subspace orthogonal to the null space of <span class="math inline">\(A\)</span> and is an <em>idempotent</em> matrix. In other words, <span class="math inline">\(\Pi^2 = \Pi\)</span>. Therefore, without loss of generality, we may assume that <span class="math inline">\(A\)</span> in <strong>?@def-matrix-approximation</strong> is an idempotent matrix <span class="math inline">\(\Pi\)</span> via the transformation described where <span class="math inline">\(A\)</span> is replaced by <span class="math inline">\(A^{+/2} A A^{+/2}\)</span> and <span class="math inline">\(v_i = A^{+/2} v_i\)</span> for all <span class="math inline">\(1 \le i \le m\)</span>.</p>
<p>With that in mind, thinking about idempotent matrices yields nice intuitions on how to think about the problem geometrically. Furthermore, for any positive semi-definite matrix <span class="math inline">\(M\)</span> we can define an ellipsoid <span class="math inline">\(\{x | x^T M x = 1\}\)</span> and for <span class="math inline">\(M = \Pi\)</span> being an idempotent matrix the ellipsoid corresponds to the sphere in the linearly transformed subspace of <span class="math inline">\(\Pi\)</span>: <span class="math display">\[x^T \Pi x = x^T \Pi \Pi x = ||\Pi x||_2^2 = 1.\]</span></p>
<p>Therefore, if we consider everything in the mapped subspace, i.e., replacing every vector <span class="math inline">\(x\)</span> with <span class="math inline">\(\Pi x\)</span> automatically, then we want to find a linear combination of their cross product such that the ellipsoid corresponding to that combination approximates a regular spherical shape. In other words, <span class="math display">\[\begin{align*}
&amp;A \approx_\epsilon \sum s_i v_i v_i^T = \hat{A}  \\
\Longleftrightarrow &amp; ~ \Pi =  A^{+/2} A A^{+/2} \approx_\epsilon \sum s_i (A^{+/2}) v_i (A^{+/2} v_i)^T = \hat{\Pi}\\
\Longleftrightarrow &amp; ~ (1 - \epsilon) \Pi \preceq \hat{\Pi} \preceq (1 + \epsilon) \Pi \\
\Longleftrightarrow &amp; ~ \forall x : (1 - \epsilon) ||\Pi x||_2^2 \le [\Pi x]^T \hat{\Pi} [\Pi x] \le (1 + \epsilon) ||\Pi x||_2^2 \\
\end{align*}\]</span></p>
<p>Therefore, the ellipsoid projected using <span class="math inline">\(\Pi\)</span> is sandwiched between two spheres off by <span class="math inline">\(\epsilon\)</span> in their radius. In turn, the algorithm takes an iterative approach to solve this geometric problem and instead of approximating matrix <span class="math inline">\(A\)</span>, it tries to approximate the matrix <span class="math inline">\(\Pi\)</span> and then obtains <span class="math inline">\(\hat{A}\)</span> by <span class="math inline">\(A^{1/2} \hat{\Pi} A^{1/2}\)</span>. It first starts off with <span class="math inline">\(X^{(0)} = \emptyset\)</span> and then iteratively picks a vector <span class="math inline">\(v_i\)</span> and assigns a weight <span class="math inline">\(s_i\)</span> to it such that the ellipsoid <span class="math inline">\(X^{(i+1)} = X^{(i)} + s_i v_i v_i^T\)</span> becomes iteratively more like a sphere (for example, by pushing on the directions that are more contracted).</p>
<p>To formalize the algorithm, it always bounds <span class="math inline">\(X^{(i)}\)</span> the corresponding ellipsoid between two spheres of radius <span class="math inline">\(l^{(i)}\)</span> and <span class="math inline">\(u^{(i)}\)</span>. At each iteration, the lower bound <span class="math inline">\(l^{(i)}\)</span> will be increased by some <span class="math inline">\(\delta_l\)</span> and the lower bound <span class="math inline">\(u^{(i)}\)</span> will be increased by some <span class="math inline">\(\delta_u\)</span> and the algorithm will try to find a vector <span class="math inline">\(v_i\)</span> and a weight <span class="math inline">\(s_i\)</span> such that the new ellipsoid <span class="math inline">\(\hat{A}^{(i+1)}\)</span> stays sandwiched between <span class="math inline">\(l^{(i+1)} = l^{(i)} + \delta_l\)</span> and <span class="math inline">\(u^{(i+1)} = u^{(i)} + \delta_u\)</span>. Moreover, a key idea here is to cleverly pick <span class="math inline">\(\delta_l\)</span> and <span class="math inline">\(\delta_u\)</span> values such that after <span class="math inline">\(k\)</span> iterations the gap between the two spheres is close and the ratio of their radius is off by at most <span class="math inline">\(\epsilon\)</span>. In other words, the following should hold: <span class="math display">\[\frac{u^{(0)} + k \delta_u}{l^{(k)} + k \delta_l} = \frac{u^{(k)}}{l^{(k)}} \le \frac{1 + \epsilon}{1 - \epsilon}.\]</span> This will ensure that the shape of the ellipsoid becomes more and more spherical as the algorithm progresses, and finally, a simple scaling on <span class="math inline">\(X^{(N)}\)</span> will yield an approximate unit sphere <span class="math inline">\(\hat{P}\)</span> which approximates <span class="math inline">\(\Pi\)</span>.</p>
<p>For illustration, <a href="#fig-ellipsoid">Figure&nbsp;1</a> shows the algorithm in action. The algorithm starts with an initial ellipsoid that is not spherical and then iteratively picks a vector <span class="math inline">\(v_i\)</span> and a weight <span class="math inline">\(s_i\)</span> such that it remains sandwiched between the two spheres. Note that in this example <span class="math inline">\(\delta_l\)</span> and <span class="math inline">\(\delta_u\)</span> are equal (but this is not the case for the final algorithm), therefore, for a large enough <span class="math inline">\(k\)</span> the ellipsoid will become more and more spherical because their radius grows while the gap between them remains constant.</p>
<div class="cell" data-execution_count="1">
<div class="sourceCode cell-code" id="cb1"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb1-1"><a href="#cb1-1" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> numpy <span class="im">as</span> np</span>
<span id="cb1-2"><a href="#cb1-2" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> matplotlib.pyplot <span class="im">as</span> plt</span>
<span id="cb1-3"><a href="#cb1-3" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> matplotlib.patches <span class="im">import</span> Ellipse</span>
<span id="cb1-4"><a href="#cb1-4" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> random </span>
<span id="cb1-5"><a href="#cb1-5" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-6"><a href="#cb1-6" aria-hidden="true" tabindex="-1"></a><span class="co"># set a seed for reproducibility</span></span>
<span id="cb1-7"><a href="#cb1-7" aria-hidden="true" tabindex="-1"></a>random.seed(<span class="dv">42</span>)</span>
<span id="cb1-8"><a href="#cb1-8" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-9"><a href="#cb1-9" aria-hidden="true" tabindex="-1"></a><span class="co"># a function to plot an ellipse</span></span>
<span id="cb1-10"><a href="#cb1-10" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> plot_ellipse(ax, A, color, alpha):</span>
<span id="cb1-11"><a href="#cb1-11" aria-hidden="true" tabindex="-1"></a>  <span class="cf">if</span> <span class="bu">len</span>(A.shape) <span class="op">==</span> <span class="dv">1</span>:</span>
<span id="cb1-12"><a href="#cb1-12" aria-hidden="true" tabindex="-1"></a>    A <span class="op">=</span> np.diag(A)</span>
<span id="cb1-13"><a href="#cb1-13" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-14"><a href="#cb1-14" aria-hidden="true" tabindex="-1"></a>  w, v <span class="op">=</span> np.linalg.eig(A)</span>
<span id="cb1-15"><a href="#cb1-15" aria-hidden="true" tabindex="-1"></a>  w <span class="op">=</span> np.sqrt(w)</span>
<span id="cb1-16"><a href="#cb1-16" aria-hidden="true" tabindex="-1"></a>  ell <span class="op">=</span> Ellipse(</span>
<span id="cb1-17"><a href="#cb1-17" aria-hidden="true" tabindex="-1"></a>    xy <span class="op">=</span> (<span class="dv">0</span>, <span class="dv">0</span>), </span>
<span id="cb1-18"><a href="#cb1-18" aria-hidden="true" tabindex="-1"></a>    width <span class="op">=</span> <span class="dv">2</span> <span class="op">*</span> w[<span class="dv">0</span>], </span>
<span id="cb1-19"><a href="#cb1-19" aria-hidden="true" tabindex="-1"></a>    height <span class="op">=</span> <span class="dv">2</span> <span class="op">*</span> w[<span class="dv">1</span>], </span>
<span id="cb1-20"><a href="#cb1-20" aria-hidden="true" tabindex="-1"></a>    angle <span class="op">=</span> np.rad2deg(np.arccos(v[<span class="dv">0</span>, <span class="dv">0</span>])), </span>
<span id="cb1-21"><a href="#cb1-21" aria-hidden="true" tabindex="-1"></a>    color <span class="op">=</span> color, </span>
<span id="cb1-22"><a href="#cb1-22" aria-hidden="true" tabindex="-1"></a>    alpha <span class="op">=</span> alpha</span>
<span id="cb1-23"><a href="#cb1-23" aria-hidden="true" tabindex="-1"></a>  )</span>
<span id="cb1-24"><a href="#cb1-24" aria-hidden="true" tabindex="-1"></a>  <span class="co"># plot the ellipse no fill</span></span>
<span id="cb1-25"><a href="#cb1-25" aria-hidden="true" tabindex="-1"></a>  ell.set_facecolor(<span class="st">'none'</span>)</span>
<span id="cb1-26"><a href="#cb1-26" aria-hidden="true" tabindex="-1"></a>  ax.add_artist(ell)</span>
<span id="cb1-27"><a href="#cb1-27" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-28"><a href="#cb1-28" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-29"><a href="#cb1-29" aria-hidden="true" tabindex="-1"></a>level <span class="op">=</span> <span class="dv">6</span></span>
<span id="cb1-30"><a href="#cb1-30" aria-hidden="true" tabindex="-1"></a>eps <span class="op">=</span> <span class="fl">1e-1</span></span>
<span id="cb1-31"><a href="#cb1-31" aria-hidden="true" tabindex="-1"></a><span class="co"># create 6 plots in a 2 by 3 grid</span></span>
<span id="cb1-32"><a href="#cb1-32" aria-hidden="true" tabindex="-1"></a>fig, axs <span class="op">=</span> plt.subplots(<span class="dv">2</span>, <span class="dv">3</span>, figsize<span class="op">=</span>(<span class="dv">12</span>, <span class="dv">8</span>))</span>
<span id="cb1-33"><a href="#cb1-33" aria-hidden="true" tabindex="-1"></a>lower_ellipse <span class="op">=</span> np.array([<span class="fl">0.25</span>, <span class="fl">0.25</span>])</span>
<span id="cb1-34"><a href="#cb1-34" aria-hidden="true" tabindex="-1"></a>upper_ellipse <span class="op">=</span> np.array([<span class="dv">1</span>, <span class="dv">1</span>])</span>
<span id="cb1-35"><a href="#cb1-35" aria-hidden="true" tabindex="-1"></a>middle_ellipse <span class="op">=</span> np.array([<span class="fl">0.25</span> <span class="op">+</span> eps, <span class="dv">1</span><span class="op">-</span>eps])</span>
<span id="cb1-36"><a href="#cb1-36" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-37"><a href="#cb1-37" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> i <span class="kw">in</span> <span class="bu">range</span>(level):</span>
<span id="cb1-38"><a href="#cb1-38" aria-hidden="true" tabindex="-1"></a>  <span class="co"># get the axs object</span></span>
<span id="cb1-39"><a href="#cb1-39" aria-hidden="true" tabindex="-1"></a>  ax <span class="op">=</span> axs[i <span class="op">//</span> <span class="dv">3</span>, i <span class="op">%</span> <span class="dv">3</span>] <span class="cf">if</span> i <span class="op">//</span> <span class="dv">3</span> <span class="op">==</span> <span class="dv">0</span> <span class="cf">else</span> axs[i <span class="op">//</span> <span class="dv">3</span>, <span class="dv">2</span> <span class="op">-</span> i <span class="op">%</span> <span class="dv">3</span>]</span>
<span id="cb1-40"><a href="#cb1-40" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-41"><a href="#cb1-41" aria-hidden="true" tabindex="-1"></a>  ax.set_title(<span class="ss">f'Iteration </span><span class="sc">{</span>i<span class="sc">}</span><span class="ss">'</span> <span class="cf">if</span> i <span class="op">&lt;</span> level <span class="op">-</span> <span class="dv">1</span> <span class="cf">else</span> <span class="st">'after rescaling'</span>)</span>
<span id="cb1-42"><a href="#cb1-42" aria-hidden="true" tabindex="-1"></a>  ax.set_xlim(<span class="op">-</span><span class="fl">2.5</span>, <span class="fl">2.5</span>)</span>
<span id="cb1-43"><a href="#cb1-43" aria-hidden="true" tabindex="-1"></a>  ax.set_ylim(<span class="op">-</span><span class="fl">2.5</span>, <span class="fl">2.5</span>)</span>
<span id="cb1-44"><a href="#cb1-44" aria-hidden="true" tabindex="-1"></a>  ax.set_aspect(<span class="st">'equal'</span>)</span>
<span id="cb1-45"><a href="#cb1-45" aria-hidden="true" tabindex="-1"></a>  plot_ellipse(ax, lower_ellipse, <span class="st">'blue'</span>, <span class="dv">1</span>)</span>
<span id="cb1-46"><a href="#cb1-46" aria-hidden="true" tabindex="-1"></a>  plot_ellipse(ax, upper_ellipse, <span class="st">'blue'</span>, <span class="dv">1</span>)</span>
<span id="cb1-47"><a href="#cb1-47" aria-hidden="true" tabindex="-1"></a>  plot_ellipse(ax, middle_ellipse, <span class="st">'red'</span>, <span class="dv">1</span>)</span>
<span id="cb1-48"><a href="#cb1-48" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-49"><a href="#cb1-49" aria-hidden="true" tabindex="-1"></a>  lower_ellipse <span class="op">+=</span> np.array([<span class="dv">1</span>, <span class="dv">1</span>])</span>
<span id="cb1-50"><a href="#cb1-50" aria-hidden="true" tabindex="-1"></a>  upper_ellipse <span class="op">+=</span> np.array([<span class="dv">1</span>, <span class="dv">1</span>])</span>
<span id="cb1-51"><a href="#cb1-51" aria-hidden="true" tabindex="-1"></a>  </span>
<span id="cb1-52"><a href="#cb1-52" aria-hidden="true" tabindex="-1"></a>  <span class="co"># flip a coin to decide which direction to push</span></span>
<span id="cb1-53"><a href="#cb1-53" aria-hidden="true" tabindex="-1"></a>  <span class="cf">if</span> random.random() <span class="op">&gt;</span> <span class="fl">0.5</span>:</span>
<span id="cb1-54"><a href="#cb1-54" aria-hidden="true" tabindex="-1"></a>    middle_ellipse[<span class="dv">0</span>] <span class="op">=</span> lower_ellipse[<span class="dv">0</span>] <span class="op">+</span> eps</span>
<span id="cb1-55"><a href="#cb1-55" aria-hidden="true" tabindex="-1"></a>    middle_ellipse[<span class="dv">1</span>] <span class="op">=</span> upper_ellipse[<span class="dv">1</span>] <span class="op">-</span> eps</span>
<span id="cb1-56"><a href="#cb1-56" aria-hidden="true" tabindex="-1"></a>  <span class="cf">else</span>:</span>
<span id="cb1-57"><a href="#cb1-57" aria-hidden="true" tabindex="-1"></a>    middle_ellipse[<span class="dv">0</span>] <span class="op">=</span> upper_ellipse[<span class="dv">0</span>] <span class="op">-</span> eps</span>
<span id="cb1-58"><a href="#cb1-58" aria-hidden="true" tabindex="-1"></a>    middle_ellipse[<span class="dv">1</span>] <span class="op">=</span> lower_ellipse[<span class="dv">1</span>] <span class="op">+</span> eps</span>
<span id="cb1-59"><a href="#cb1-59" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-60"><a href="#cb1-60" aria-hidden="true" tabindex="-1"></a>  <span class="cf">if</span> i <span class="op">==</span> level <span class="op">-</span> <span class="dv">2</span>:</span>
<span id="cb1-61"><a href="#cb1-61" aria-hidden="true" tabindex="-1"></a>    <span class="co"># do rescaling</span></span>
<span id="cb1-62"><a href="#cb1-62" aria-hidden="true" tabindex="-1"></a>    lower_ellipse <span class="op">=</span> lower_ellipse <span class="op">/</span> (level <span class="op">-</span> <span class="fl">1.0</span>)</span>
<span id="cb1-63"><a href="#cb1-63" aria-hidden="true" tabindex="-1"></a>    upper_ellipse <span class="op">=</span> upper_ellipse <span class="op">/</span> (level <span class="op">-</span> <span class="fl">1.0</span>)</span>
<span id="cb1-64"><a href="#cb1-64" aria-hidden="true" tabindex="-1"></a>    middle_ellipse <span class="op">=</span> middle_ellipse <span class="op">/</span> (level <span class="op">-</span> <span class="fl">1.0</span>)</span>
<span id="cb1-65"><a href="#cb1-65" aria-hidden="true" tabindex="-1"></a>plt.show()</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display">
<div id="fig-ellipsoid" class="quarto-figure quarto-figure-center anchored">
<figure class="figure">
<p><img src="method_files/figure-html/fig-ellipsoid-output-1.png" width="941" height="647" class="figure-img"></p>
<p></p><figcaption class="figure-caption">Figure&nbsp;1: The geometric intuition behind the algorithm.</figcaption><p></p>
</figure>
</div>
</div>
</div>
</section>
<section id="physical-view-and-the-expected-behavior" class="level2">
<h2 class="anchored" data-anchor-id="physical-view-and-the-expected-behavior">Physical View and the Expected behavior</h2>
<p>The fact that <span class="math inline">\(X^{(i)}\)</span> should be bounded between two spheres translates into all the eigenvalues of <span class="math inline">\(X^{(i)}\)</span> being bounded between the two radiuses except for the trivial eigenvalues that their corresponding eigenvector is in the null-space of <span class="math inline">\(\Pi\)</span>. For Laplacians, this corresponds to the all oneâ€™s vector which is in the null-space of <span class="math inline">\(L_G\)</span> and <span class="math inline">\(\Pi = L_G^{+/2} L_G L_G^{+/2}\)</span>. For simplicity, we assume that all the matrices are full rank and <span class="math inline">\(\Pi = I\)</span>. Using this, we can establish theories that easily generalize to the case where <span class="math inline">\(\Pi\)</span> is not the identity matrix via projection.</p>
<p>An important observation is to monitor what happens to the eigenvalues of <span class="math inline">\(X^{(i)}\)</span> when <span class="math inline">\(vv^T\)</span> is being added at each iteration. To do so, we consider the characteristic polynomial of <span class="math inline">\(X\)</span> at each iteration written as <span class="math inline">\(p_X(\lambda) = \det(\lambda I - X)\)</span>. There are two important lemmas when analyzing <span class="math inline">\(A + vv^T\)</span> matrices, one is the Sherman-Morrison lemma which states that:</p>
<div id="lem-sherman-morrison" class="theorem lemma">
<p><span class="theorem-title"><strong>Lemma 1 </strong></span>Suppose <span class="math inline">\(A\)</span> is an invertible square matrix and <span class="math inline">\(u, v\)</span> are column vectors. Then <span class="math inline">\(A + uv^T\)</span> is invertible iff <span class="math inline">\(1 + v^T A^{-1} u \neq 0\)</span>. In this case, <span class="math display">\[(A + uv^T)^{-1} = A^{-1} - \frac{A^{-1}uv^TA^{-1}}{1 + v^TA^{-1}u}\]</span></p>
</div>
<p>The other is the matrix determinant lemma which states that:</p>
<div id="lem-matrix-determinant" class="theorem lemma">
<p><span class="theorem-title"><strong>Lemma 2 </strong></span>Suppose <span class="math inline">\(A\)</span> is an invertible square matrix and <span class="math inline">\(u, v\)</span> are column vectors. Then <span class="math display">\[\det(A + uv^T) = \det(A) (1 + v^T A^{-1} u)\]</span></p>
</div>
<p>Moreover, plugging these into the characteristic polynomial of <span class="math inline">\(X + vv^T\)</span> yields the following:</p>
<p><span class="math display">\[\begin{align*}
p_{X + vv^T}(\lambda) &amp;= \det(\lambda I - X - vv^T) \\
&amp; = \det(\lambda I - X) (1 - v^T \left(\lambda I - X \right)^{-1}u) \\
&amp; = \det (\lambda I - X) \left(1 - v^T \left[\sum_{i=1}^n \frac{1}{\lambda - \lambda_i} u_i u_i^T\right] v\right)\\
&amp; = p_X(\lambda) \left(1 -  \sum_{i=1}^n \frac{(v^Tu_i)^2}{\lambda - \lambda_i}\right)\\
\end{align*}\]</span></p>
<p>Furthermore, we can assume particles being set on certain points of the <span class="math inline">\(x\)</span>-axis with the <span class="math inline">\(i\)</span>th one on <span class="math inline">\(\lambda_i\)</span> having a charge equal to <span class="math inline">\((v^Tu_i)^2\)</span>. The new set of equilibrium points for this particle set will entail the new eigenvalues of <span class="math inline">\(X + vv^T\)</span> which are the roots of <span class="math inline">\(p_{X + vv^T}(\lambda)\)</span>. Note that for <span class="math inline">\(u_i\)</span> values such that <span class="math inline">\(v^Tu_i=0\)</span> the charge is zero and therefore, the new eigenvalues will be the same as the old ones.</p>
<p>The following figure illustrates the matrix case <span class="math inline">\(X\)</span> with three different vectors <span class="math inline">\(v_1\)</span>, <span class="math inline">\(v_2\)</span> and <span class="math inline">\(v_3\)</span>. Each color corresponds to the characteristic polynomial for different <span class="math inline">\(v\)</span> values where,</p>
<p><span class="math display">\[X = \lambda_1 u_1 u_1^T + \lambda_2 u_2 u_2^T + \lambda_3 u_3 u_3^T
= \begin{bmatrix}
1.6 &amp; -0.2 &amp; -0.33\\
-0.2 &amp; 3.4 &amp; -0.33\\
-0.33 &amp; -0.33 &amp; 1
\end{bmatrix}\]</span> <span class="math display">\[\begin{bmatrix}\lambda_1 \\ \lambda_2 \\ \lambda_3\end{bmatrix} = \begin{bmatrix}0.79 \\ 1.75 \\ 3.46\end{bmatrix}, u_1 = \begin{bmatrix}
-0.41\\
-0.15\\
-0.9
\end{bmatrix}, u_2 = \begin{bmatrix}
-0.9 \\
-0.03 \\
0.42
\end{bmatrix}, u_3 = \begin{bmatrix}
0.08\\
-0.99\\
0.12\\
\end{bmatrix}\]</span> We note that <span class="math inline">\(\langle v_i, u_j \rangle^2\)</span> is the charge of particle <span class="math inline">\(j\)</span> when adding <span class="math inline">\(v_i\)</span> to <span class="math inline">\(X\)</span> and we can summarize all the charged particles in the following matrix: <span class="math display">\[v_1 = \begin{bmatrix}
0\\
1\\
1\\
\end{bmatrix}, v_2 = \begin{bmatrix}
1\\
1\\
0\\
\end{bmatrix},
C = \begin{bmatrix}
1.10 &amp; 0.15 &amp; 0.75\\
0.31 &amp; 0.87 &amp; 0.82
\end{bmatrix}, C_{ij} = \langle v_i, u_j \rangle^2\]</span></p>
<div>
<div class="sourceCode cell-code" id="cb2"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb2-1"><a href="#cb2-1" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> numpy <span class="im">as</span> np</span>
<span id="cb2-2"><a href="#cb2-2" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> matplotlib.pyplot <span class="im">as</span> plt</span>
<span id="cb2-3"><a href="#cb2-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb2-4"><a href="#cb2-4" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> plot_characteristic_polynomial(w, u, v, color):</span>
<span id="cb2-5"><a href="#cb2-5" aria-hidden="true" tabindex="-1"></a>  x <span class="op">=</span> np.linspace(<span class="op">-</span><span class="dv">25</span>, <span class="dv">50</span>, <span class="dv">1000</span>)</span>
<span id="cb2-6"><a href="#cb2-6" aria-hidden="true" tabindex="-1"></a>  <span class="co"># plot the determinant of xI - (X + vv^T)</span></span>
<span id="cb2-7"><a href="#cb2-7" aria-hidden="true" tabindex="-1"></a>  <span class="co"># for X = u w u^T</span></span>
<span id="cb2-8"><a href="#cb2-8" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb2-9"><a href="#cb2-9" aria-hidden="true" tabindex="-1"></a>  y <span class="op">=</span> []</span>
<span id="cb2-10"><a href="#cb2-10" aria-hidden="true" tabindex="-1"></a>  roots <span class="op">=</span> []</span>
<span id="cb2-11"><a href="#cb2-11" aria-hidden="true" tabindex="-1"></a>  prv <span class="op">=</span> <span class="dv">0</span></span>
<span id="cb2-12"><a href="#cb2-12" aria-hidden="true" tabindex="-1"></a>  <span class="cf">for</span> i <span class="kw">in</span> x:</span>
<span id="cb2-13"><a href="#cb2-13" aria-hidden="true" tabindex="-1"></a>    val <span class="op">=</span> <span class="dv">1</span> <span class="op">-</span> np.<span class="bu">sum</span>(<span class="dv">1</span><span class="op">/</span>(i <span class="op">-</span> w) <span class="op">*</span> (v <span class="op">@</span> u)<span class="op">**</span><span class="dv">2</span>)</span>
<span id="cb2-14"><a href="#cb2-14" aria-hidden="true" tabindex="-1"></a>    <span class="cf">if</span> prv <span class="op">&lt;</span> <span class="dv">0</span> <span class="kw">and</span> val <span class="op">&gt;</span> <span class="dv">0</span>:</span>
<span id="cb2-15"><a href="#cb2-15" aria-hidden="true" tabindex="-1"></a>      roots.append(i)</span>
<span id="cb2-16"><a href="#cb2-16" aria-hidden="true" tabindex="-1"></a>    prv <span class="op">=</span> val</span>
<span id="cb2-17"><a href="#cb2-17" aria-hidden="true" tabindex="-1"></a>    y.append(val)</span>
<span id="cb2-18"><a href="#cb2-18" aria-hidden="true" tabindex="-1"></a>  plt.plot(x, y, color <span class="op">=</span> color, <span class="op">\</span></span>
<span id="cb2-19"><a href="#cb2-19" aria-hidden="true" tabindex="-1"></a>    label<span class="op">=</span><span class="st">'characteristic polynomial of X + vv^T'</span>)</span>
<span id="cb2-20"><a href="#cb2-20" aria-hidden="true" tabindex="-1"></a>  plt.scatter(roots, np.zeros(<span class="bu">len</span>(roots)), color <span class="op">=</span> color,<span class="op">\</span></span>
<span id="cb2-21"><a href="#cb2-21" aria-hidden="true" tabindex="-1"></a>    marker <span class="op">=</span> <span class="st">'o'</span>, label<span class="op">=</span><span class="st">'new-eigenvalues'</span>)</span>
<span id="cb2-22"><a href="#cb2-22" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb2-23"><a href="#cb2-23" aria-hidden="true" tabindex="-1"></a><span class="co"># create an orthonormal 3 by 3 matrix U</span></span>
<span id="cb2-24"><a href="#cb2-24" aria-hidden="true" tabindex="-1"></a>U <span class="op">=</span> np.array([[<span class="op">-</span><span class="fl">0.41</span>, <span class="op">-</span><span class="fl">0.15</span>, <span class="op">-</span><span class="fl">0.9</span>],</span>
<span id="cb2-25"><a href="#cb2-25" aria-hidden="true" tabindex="-1"></a>              [<span class="op">-</span><span class="fl">0.9</span>, <span class="op">-</span><span class="fl">0.03</span>, <span class="fl">0.42</span>], </span>
<span id="cb2-26"><a href="#cb2-26" aria-hidden="true" tabindex="-1"></a>              [<span class="fl">0.08</span>, <span class="op">-</span><span class="fl">0.99</span>, <span class="fl">0.12</span>]]).T</span>
<span id="cb2-27"><a href="#cb2-27" aria-hidden="true" tabindex="-1"></a>w <span class="op">=</span> np.array([<span class="fl">0.79</span>, <span class="fl">1.75</span>, <span class="fl">3.46</span>])</span>
<span id="cb2-28"><a href="#cb2-28" aria-hidden="true" tabindex="-1"></a>A <span class="op">=</span> U <span class="op">@</span> np.diag(w) <span class="op">@</span> U.T</span>
<span id="cb2-29"><a href="#cb2-29" aria-hidden="true" tabindex="-1"></a>vz <span class="op">=</span> [[<span class="dv">0</span>, <span class="dv">1</span>, <span class="dv">1</span>], [<span class="dv">1</span>, <span class="dv">1</span>, <span class="dv">0</span>]]</span>
<span id="cb2-30"><a href="#cb2-30" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb2-31"><a href="#cb2-31" aria-hidden="true" tabindex="-1"></a><span class="co"># plot two different graphs</span></span>
<span id="cb2-32"><a href="#cb2-32" aria-hidden="true" tabindex="-1"></a>colors <span class="op">=</span> [<span class="st">'blue'</span>, <span class="st">'red'</span>]</span>
<span id="cb2-33"><a href="#cb2-33" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb2-34"><a href="#cb2-34" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> col, v <span class="kw">in</span> <span class="bu">zip</span>(colors, vz):</span>
<span id="cb2-35"><a href="#cb2-35" aria-hidden="true" tabindex="-1"></a>  plt.scatter(w, np.zeros(w.shape), color <span class="op">=</span> <span class="st">'black'</span>, marker <span class="op">=</span> <span class="st">'x'</span>, label<span class="op">=</span><span class="st">'previous eigenvalues'</span>)</span>
<span id="cb2-36"><a href="#cb2-36" aria-hidden="true" tabindex="-1"></a>  <span class="co"># add text with textbox equal to np.sum(w) on top of each eigenvalue</span></span>
<span id="cb2-37"><a href="#cb2-37" aria-hidden="true" tabindex="-1"></a>  <span class="cf">for</span> i, wi <span class="kw">in</span> <span class="bu">enumerate</span>(w):</span>
<span id="cb2-38"><a href="#cb2-38" aria-hidden="true" tabindex="-1"></a>    t <span class="op">=</span> plt.text(wi <span class="op">-</span> <span class="fl">0.5</span>, <span class="fl">0.1</span> <span class="op">*</span> (<span class="dv">4</span> <span class="op">*</span> (i <span class="op">%</span> <span class="dv">2</span>) <span class="op">-</span> <span class="fl">2.5</span>), <span class="op">\</span></span>
<span id="cb2-39"><a href="#cb2-39" aria-hidden="true" tabindex="-1"></a>      <span class="ss">f"c=</span><span class="sc">{</span>(v <span class="op">@</span> U[:,i])<span class="op">**</span><span class="dv">2</span><span class="sc">:.2f}</span><span class="ss">"</span>, color <span class="op">=</span> <span class="st">'black'</span>)</span>
<span id="cb2-40"><a href="#cb2-40" aria-hidden="true" tabindex="-1"></a>    t.set_bbox(<span class="bu">dict</span>(facecolor<span class="op">=</span><span class="st">'white'</span>, alpha<span class="op">=</span><span class="fl">0.5</span>, edgecolor<span class="op">=</span>col))</span>
<span id="cb2-41"><a href="#cb2-41" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb2-42"><a href="#cb2-42" aria-hidden="true" tabindex="-1"></a>  plot_characteristic_polynomial(w, U, v, col)</span>
<span id="cb2-43"><a href="#cb2-43" aria-hidden="true" tabindex="-1"></a>  plt.xlim(<span class="dv">0</span>, <span class="fl">5.5</span>)</span>
<span id="cb2-44"><a href="#cb2-44" aria-hidden="true" tabindex="-1"></a>  plt.ylim(<span class="op">-</span><span class="dv">2</span>, <span class="dv">2</span>)</span>
<span id="cb2-45"><a href="#cb2-45" aria-hidden="true" tabindex="-1"></a>  plt.legend()</span>
<span id="cb2-46"><a href="#cb2-46" aria-hidden="true" tabindex="-1"></a>  plt.show()</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div id="fig-matrix-determinant" class="cell quarto-layout-panel" data-execution_count="2">
<figure class="figure">
<div class="quarto-layout-row quarto-layout-valign-top">
<div class="cell-output cell-output-display quarto-layout-cell quarto-layout-cell-subref" style="flex-basis: 50.0%;justify-content: center;">
<div id="fig-matrix-determinant-1" class="quarto-figure quarto-figure-center anchored">
<figure class="figure">
<p><img src="method_files/figure-html/fig-matrix-determinant-output-1.png" class="img-fluid figure-img" data-ref-parent="fig-matrix-determinant" width="582"></p>
<p></p><figcaption class="figure-caption">(a) The characteristic polynomial after adding <span class="math inline">\(v_1\)</span> to X.</figcaption><p></p>
</figure>
</div>
</div>
<div class="cell-output cell-output-display quarto-layout-cell quarto-layout-cell-subref" style="flex-basis: 50.0%;justify-content: center;">
<div id="fig-matrix-determinant-2" class="quarto-figure quarto-figure-center anchored">
<figure class="figure">
<p><img src="method_files/figure-html/fig-matrix-determinant-output-2.png" class="img-fluid figure-img" data-ref-parent="fig-matrix-determinant" width="582"></p>
<p></p><figcaption class="figure-caption">(b) The characteristic polynomial after adding <span class="math inline">\(v_2\)</span> to X.</figcaption><p></p>
</figure>
</div>
</div>
</div>
<p></p><figcaption class="figure-caption">Figure&nbsp;2: The characteristic polynomial of <span class="math inline">\(X + vv^T\)</span> for different <span class="math inline">\(v\)</span> values, the higher the charge the more it will repel the new eigenvalues from the old ones.</figcaption><p></p>
</figure>
</div>
</div>
<p>The goal is to pick a <span class="math inline">\(v\)</span> such that the particles are set in a way that all the eigenvalues are uniformly pushed forward so that they can stay between the new ranges <span class="math inline">\(l^{(i+1)}\)</span> and <span class="math inline">\(u^{(i+1)}\)</span>. To get a sense, letâ€™s pick one of the <span class="math inline">\(m\)</span> vectors with uniform probability and add it to <span class="math inline">\(X\)</span>. In that case, the expected charges can be written as: <span class="math display">\[E[\langle v, u_j \rangle^2] = \frac{1}{m} \sum_{i=1}^m \langle v_i, u_j \rangle^2 = \frac{1}{m} u_j^T \left( \sum_{i=1}^m v_i v_i^T \right)u_j = \frac{||\Pi u_j||_2^2}{m} = \frac{1}{m}\]</span> Hence, on expectation, all the particles have a charge of <span class="math inline">\(1/m\)</span> and the expected deterministic polynomial is:</p>
<p><span class="math display">\[\begin{align*}
E[p_{X + v}(\lambda)] &amp;= p_X(\lambda) E\left[1 - \sum_{i=1}^m \frac{\langle u_i, v\rangle^2}{\lambda - \lambda_i}\right] = p_X(\lambda) \left(1 - \sum_{i=1}^m \frac{E\langle u_i, v\rangle^2}{\lambda - \lambda_i}\right)\\
&amp; = p_X(\lambda) \left(1 - \sum_{i=1}^m \frac{1/m}{\lambda - \lambda_i}\right) = p_X(\lambda) - \frac{1}{m} \sum_{i=1}^m \frac{p_X(\lambda)}{\lambda - \lambda_i}\\
&amp; = p_X(\lambda) - \frac{1}{m} \sum_{i=1}^m \prod_{1 = j\neq i}^m (\lambda - \lambda_j)\\
&amp;= p_X(\lambda) - \frac{1}{m} p'_X(\lambda)\\
\end{align*}\]</span></p>
<p>Therefore, if we start with the matrix <span class="math inline">\(p_{X^{(0)}}(\lambda) = \lambda^n\)</span>, after <span class="math inline">\(nd\)</span> iterations the expected polynomial is a set of associate Laguerre polynomials that are well studied <span class="citation" data-cites="dette1995some">[@dette1995some]</span>, and in particular, it has been proven that the ratio between the largest and smallest root for these polynomials is bounded by the value below:</p>
<p><span class="math display">\[\frac{d + 1 + 2\sqrt{d}}{d + 1 - 2\sqrt{d}} \xrightarrow{\epsilon = \frac{2\sqrt{d}}{d+1}} \frac{1 + \epsilon
}{1 - \epsilon}\]</span></p>
<p>Although this is just speculation and no <span class="math inline">\(v_i\)</span> values will necessarily exist with the expected behavior, we can still get an idea of the goal <span class="math inline">\(\epsilon\)</span> and come up with the following proposition:</p>
<div id="prp-final-form" class="theorem proposition">
<p><span class="theorem-title"><strong>Proposition 1 </strong></span>For any matrix <span class="math inline">\(A = \sum_{i=1}^m v_i v_i^T\)</span> we can choose a subset <span class="math inline">\(\mathcal{S}\)</span> of <span class="math inline">\(v_i\)</span> and a set of coefficients <span class="math inline">\(s_i\)</span> with size <span class="math inline">\(nd\)</span> such that: <span class="math display">\[\hat{A} = \sum_{i \in \mathcal{S}} s_i \cdot v_i v_i^T,~~ (1 - \frac{2\sqrt{d}}{d+1}) A \preceq \hat{A} \preceq (1 + \frac{2\sqrt{d}}{d+1}) A\]</span></p>
</div>
<p>The graph formulation of <a href="#prp-final-form">Proposition&nbsp;1</a> is as follows:</p>
<div id="cor-final-form" class="theorem corollary">
<p><span class="theorem-title"><strong>Corollary 1 </strong></span>For any graph <span class="math inline">\(G\)</span> and any <span class="math inline">\(\epsilon\)</span> we can choose a subset of <span class="math inline">\(\mathcal{O}(n/\epsilon^2)\)</span> edges with arbitrary edge weights to obtain <span class="math inline">\(H\)</span> such that <span class="math inline">\(H\)</span> is an <span class="math inline">\(\epsilon\)</span>-sparsifier of <span class="math inline">\(G\)</span>: <span class="math inline">\(L_G \approx_\epsilon L_H\)</span>.</p>
</div>
<p>This is set using <span class="math inline">\(\epsilon = \frac{2\sqrt{d}}{d + 1}\)</span> where <span class="math inline">\(\frac{n}{\epsilon^2} = \mathcal{O}(nd)\)</span>. In the next section, we will see how we can choose <span class="math inline">\(v_i\)</span> and <span class="math inline">\(s_i\)</span> at each step such that after <span class="math inline">\(nd\)</span> iterations this happens.</p>
<section id="potential-functions" class="level3">
<h3 class="anchored" data-anchor-id="potential-functions">Potential Functions</h3>
<p>The big question is, how can we quantize the boundedness of the matrix <span class="math inline">\(X\)</span> at each step? We want <span class="math inline">\(X^{(i)}\)</span> to have eigenvalues that are bounded by <span class="math inline">\(l^{(i+1)}\)</span> and <span class="math inline">\(u^{(i+1)}\)</span>; and so, we use a family of <strong>potential functions</strong> that explode when the eigenvalues approach the bounds. A set of such potentials can be chosen using the fact that <span class="math inline">\(uI - X\)</span> or <span class="math inline">\(A - lX\)</span> will have infinitely small eigenvalues when the eigenvalues of <span class="math inline">\(X\)</span> approach <span class="math inline">\(u\)</span> or <span class="math inline">\(l\)</span> respectively; therefore, their inverse will be ill-conditioned and have infinitely large eigenvalues. We can use the following potential functions:</p>
<p><span class="math display">\[\Phi^u_l(X) = \Phi^u(X) + \Phi_l(X) = Tr[(uI - X)^{-1}] + Tr[(X - l I)^{-1}]\]</span></p>
<p>In summary, the main idea is to choose <span class="math inline">\(v_i\)</span> and <span class="math inline">\(s_i\)</span> such that the potential for the matrix <span class="math inline">\(X^{(i)}\)</span> in the next iteration does not explode. To do so, we can ensure that the potentials remain monotonically decreasing:</p>
<p><span class="math display">\[\infty \gg \Phi^{u^{(0)}}(X^{(0)}) \ge \Phi^{u^{(1)}}(X^{(1)}) \ge ... \ge \Phi^{u^{(nd)}}(X^{(nd)})\]</span> <span class="math display">\[\infty \gg \Phi_{\ell^{(0)}}(X^{(0)}) \ge \Phi_{\ell^{(1)}}(X^{(1)}) \ge ... \ge \Phi_{\ell^{(nd)}}(X^{(nd)})\]</span></p>
<p>With that in mind, letâ€™s assume we are going to assign <span class="math inline">\(s_k\)</span> to any vector <span class="math inline">\(v_k\)</span> such that after the increase in our upper and lower bound, the potential remains non-increasing. Now let us separately consider the upper and lower bound potentials.</p>
<p>When increasing <span class="math inline">\(l^{(i)}\)</span>, the eigenvalues come closer to the lower bound, and hence, the potential of the lower bound will increase; therefore, for any vector <span class="math inline">\(v_k\)</span>, the coefficient <span class="math inline">\(s_k\)</span> should be bounded by some value <span class="math inline">\(L_{X^{(i)}}(v_k)\)</span> such that after adding <span class="math inline">\(s_k \cdot v_k v_k^T\)</span> to <span class="math inline">\(X^{(i)}\)</span>, spectrum shifts forward and the increase in the potential cancels out. That said, for any matrix <span class="math inline">\(X\)</span> and any vector <span class="math inline">\(v\)</span> we have: <span class="math display">\[
\begin{align*}
&amp;\Phi^{\overset{l'}{\overbrace{l + \delta_l}}}(X + s \cdot vv^T) \le \Phi^l(X)\\
\Phi_{l'}(X + s \cdot vv^T) &amp; = Tr(X + s \cdot vv^T - l'I)^{-1}  \qquad \text{Sherman-Morrison}\\\
&amp; = Tr\left((X - l'I)^{-1}\right) + Tr\left(\frac{s \cdot (X - l'I)^{-1} v v^T (X - l'I)^{-1}}{1 + s \cdot v^T (X - l' I)^{-1} v}\right)\\
&amp;= \Phi_{l'}(X) - \frac{s \cdot v^T (X - l'I)^{-2}v}{1 + s \cdot v^T  (X - l'I)^{-1}v} \le \Phi^l(X)\\
\Leftrightarrow &amp;~ \underset{\Delta}{\underbrace{\Phi_{l'}(X) - \Phi^l(X)}} \le \frac{s \cdot v^T (X - l'I)^{-2}v}{1 + s \cdot v^T  (X - l'I)^{-1}v}\\
\Leftrightarrow &amp;~ s\cdot \left[v^T (X - l'I)^{-2}v  - \Delta v^T(X - l' I)^{-1} v\right] \ge \Delta \\
\Leftrightarrow &amp;~ s \ge \frac{\Delta}{v^T \left( (X - l'I)^{-2} - \Delta (X - l' I)^{-1} \right) v} = L_X(v)
\end{align*}
\]</span> which means,</p>
<p><span class="math display">\[\begin{equation} \tag{1}\label{eq:lower-bound-potential}
s \ge L_X(v) = \frac{\Delta}{v^T \left((X - l' I)^{-2} - \Delta (X - l' I)^{-1} \right) v}
\end{equation}\]</span></p>
<p>On the other hand, a similar thing can be said for the upper-bound potential. when increasing <span class="math inline">\(u^{(i)}\)</span>, the eigenvalues are further away from the upper bound which gives us the freedom to shift the eigenvalues forward. However, this shifting should not be so extreme that the potential at most increases to offset the decrease introduced after adding <span class="math inline">\(\delta_u\)</span> to <span class="math inline">\(u^{(i)}\)</span>: <span class="math display">\[
\Phi^{\overset{u'}{\overbrace{u + \delta_u}}}(A + s \cdot vv^T) \le \Phi^u(A).
\]</span> Similar to <span class="math inline">\(\eqref{eq:lower-bound-potential}\)</span>, if we negate <span class="math inline">\(s\)</span> and <span class="math inline">\(A\)</span> then the upper-bound potential will act similarly to the lower-bound potential. Therefore, we can write the following:</p>
<p><span class="math display">\[\begin{equation} \tag{2}\label{eq:upper-bound-potential}
s \le U_X(v) = \frac{\Delta}{v^T \left((u' I - X)^{-2} - \Delta (u' I - X)^{-1}\right)v}
\end{equation}\]</span></p>
<p>Where <span class="math inline">\(\Delta\)</span> is the difference between <span class="math inline">\(\Phi^u(X)\)</span> and <span class="math inline">\(\Phi^{u'}(X)\)</span>.</p>
<p>Finally, for every vector <span class="math inline">\(v_i\)</span> at each step, we can introduce an upper and lower bound for the coefficient corresponding to that vector. However, this is not enough to ensure that at least one <span class="math inline">\(v_i\)</span> exists such that <span class="math inline">\(L_X(v_i) \le U_X(v_i)\)</span>; in other words, it might be the case that for each vector the upper and lower bounds are contradictory which will put the algorithm in a stale-mate state. To avoid this, we pick the values <span class="math inline">\(\delta_u\)</span> and <span class="math inline">\(\delta_l\)</span> carefully and introduce a nice lemma in the next section that ensures such a vector always exists.</p>
</section>
<section id="the-existence-of-a-good-vector" class="level3">
<h3 class="anchored" data-anchor-id="the-existence-of-a-good-vector">The Existence of a good Vector</h3>
<p>We will now present the following lemma, that for the potentials having a certain condition, a good vector <span class="math inline">\(v_k\)</span> and a good coefficient <span class="math inline">\(s_k\)</span> always exist. This is the meat and bones of the algorithm:</p>
<div id="lem-good-vector-existance" class="theorem lemma">
<p><span class="theorem-title"><strong>Lemma 3 </strong></span>For any set of vectors <span class="math inline">\(\langle v_1, v_2, ..., v_m \rangle\)</span> that sum up to an idempotent matrix <span class="math inline">\(\Pi = \sum v_i v_i^T\)</span> and a matrix <span class="math inline">\(X\)</span> being an arbitrary linear combination of their rank one cross product, if <span class="math inline">\(\Phi^u(X) \le \epsilon_U\)</span> and <span class="math inline">\(\Phi_l(X) \le \epsilon_L\)</span> and <span class="math inline">\(\epsilon_u, \epsilon_l, \delta_u, \delta_l\)</span> satisfy the following conditions: <span class="math display">\[0 \le \delta_u^{-1} + \epsilon_u \le \delta_l^{-1} - \epsilon_l,\]</span> Then, there exists a vector <span class="math inline">\(v_k\)</span> such that: <span class="math display">\[L_X(v_k) \le U_X(v_k)\]</span> , and hence, by adding <span class="math inline">\(s \cdot v_k v_k^T\)</span> to <span class="math inline">\(X\)</span> for <span class="math inline">\(s \in [L_A(v_k), U_A(v_k)]\)</span>, we can ensure that <span class="math inline">\(\Phi^{u + \delta_u}(X + s \cdot v_k v_k^T) \le \Phi^{u}(X)\)</span> and <span class="math inline">\(\Phi_{l + \delta_l}(X + s \cdot v_k v_k^T) \le \Phi_l(X)\)</span>.</p>
</div>
<div class="solution proof">
<p><span class="proof-title"><em>Solution</em>. </span>The proof idea is to show that the sum of all the lower bound values for all the vectors <span class="math inline">\(v_k\)</span> is less than or equal to the sum of all the upper bounds for all vectors <span class="math inline">\(v_k\)</span>. In other words, <span class="math display">\[\sum_{k=1}^m L_X(v_k) \le \sum_{k=1}^m U_X(v_k)\]</span> The proof in <span class="citation" data-cites="batson2009twice">[@batson2009twice]</span> shows that the left-hand-side is bounded by <span class="math inline">\(\frac{1}{\delta_l^{-1} - \epsilon_l}\)</span> and the right-hand-side is bounded by <span class="math inline">\(\frac{1}{\delta_u^{-1} + \epsilon_u}\)</span>. Therefore, the lemma is proven using the conditions mentioned.</p>
<p>To show these two bounds, a lot of algebra is required. The proof is hidden here for brevity but you can check out the proof of Lemma 3.5 and Claim 3.6 in <span class="citation" data-cites="batson2009twice">[@batson2009twice]</span> for more details; although, they have used a different notation and instead of bounding <span class="math inline">\(s_k\)</span> values they bound their reciprocals.</p>
</div>
<p>Now we should pick values that adhere to the conditions: <span class="math display">\[\delta_l = 1, \delta_u = \frac{\sqrt{d} + 1}{ \sqrt{d} - 1}, l^{(0)} = -n \sqrt{d}, u^{(0)} = \frac{n(d+\sqrt{d})}{(\sqrt{d} -1)}\]</span></p>
<p>Note that in this case, in the first step (starting off with <span class="math inline">\(X^{(0)} = 0\)</span>), the upper and lower potentials are upper-bounded as follows: <span class="math display">\[\Phi^u(X^{(0)}) = Tr(u^{(0)}I)^{-1} = \frac{n}{u^{0}} = \frac{\sqrt{d} - 1}{\sqrt{d} + d} = \epsilon_u\]</span> <span class="math display">\[\Phi_l(X^{(0)}) = Tr(-l^{(0)} I)^{-1} = \frac{n}{l^{0}} = \frac{1}{\sqrt{d}} = \epsilon_l\]</span></p>
<p>Hence, if we plug in the criteria we have, <span class="math display">\[
0 \le
\frac{d-1}{d + \sqrt{d}} = \underset{\delta_u^{-1}}{\underbrace{\frac{\sqrt{d} - 1}{\sqrt{d} + 1}}} + \underset{\epsilon_u}{\underbrace{\frac{\sqrt{d}-1}{\sqrt{d}+d}}} = \underset{\delta_l^{-1}}{\underbrace{1}} - \underset{\epsilon_l}{\underbrace{\frac{1}{\sqrt{d}}}} = \frac{\sqrt{d} - 1}{\sqrt{d}}
\]</span> which is satisfactory.</p>
<p>Finally, we know that after <span class="math inline">\(nd\)</span> iterations <span class="math inline">\(X^{(nd)}\)</span> will be bounded between the two following spheres:</p>
<p><span class="math display">\[\begin{align*}
&amp;~~(l^{(0)} + nd \cdot \delta_l) I \preceq X^{(nd)} \preceq (u^{(0)} + nd \cdot \delta_u) I\\
\Leftrightarrow &amp; ~~ (nd - n \sqrt{d}) I \preceq X^{(nd)} \preceq \left(\frac{nd (\sqrt{d} + 1)}{\sqrt{d} - 1} + \frac{n(d + \sqrt{d})}{\sqrt{d} - 1}\right) I
\end{align*}\]</span></p>
<p>Then by rescaling both sides of the equations by <span class="math inline">\(\gamma = \frac{\sqrt{d} - 1}{n(d+1)\sqrt{d}}\)</span>, we have that,</p>
<p><span class="math display">\[\begin{equation} \tag{3} \label{eq:rescaling}
(1 - \frac{2\sqrt{d}}{d+1}) I \preceq \gamma \cdot X^{(nd)} \preceq (1 + \frac{2\sqrt{d}}{d+1}) I
\end{equation}\]</span> If we multiply both sides with <span class="math inline">\(A^{+/2}\)</span> and setting <span class="math inline">\(\epsilon = \frac{2\sqrt{d}}{d + 1}\)</span>, we get that, <span class="math display">\[
(1 - \epsilon) A \preceq \gamma \cdot A^{1/2} X^{(nd)} A^{1/2} \preceq (1 + \epsilon) A
\]</span> In turn, <span class="math inline">\(A^{1/2} X^{(nd)} A^{1/2}\)</span> would give us the Laplacian <span class="math inline">\(L_H\)</span> in the original problem.</p>
</section>
<section id="the-deterministic-algorithm" class="level3">
<h3 class="anchored" data-anchor-id="the-deterministic-algorithm">The Deterministic Algorithm</h3>
<p>Now that we have a general sense of the algorithm, we can do a recap of what the algorithm does:</p>
<ol type="1">
<li><p>We will first map each edge to a vector <span class="math inline">\(v_e = \sqrt{w_e} L_G^{+/2} (\chi_{e_1} - \chi_{e_2})\)</span> where <span class="math inline">\(w_e\)</span> is the weight of the edge and <span class="math inline">\(\chi_{e_i}\)</span> is the indicator vector of the vertex <span class="math inline">\(e_i\)</span>.</p></li>
<li><p>We start with the all-zeros matrix <span class="math inline">\(X\)</span> which is intended to approximate the spherically shaped idempotent matrix <span class="math inline">\(\Pi = L_G^{+/2} L_G L_G^{+/2}\)</span>.</p></li>
<li><p>To do so, we run <span class="math inline">\(nd\)</span> iterations and pick an edge corresponding to a vector <span class="math inline">\(v_i\)</span> in each iteration such that the potentials remain monotonically non-increasing.</p>
<ol type="i">
<li>For that, we compute the lower and upper bounds for the coefficients. For all the potential computations, we consider the edges in the <span class="math inline">\(n-1\)</span>-dimensional subspace after applying <span class="math inline">\(L_G^{+/2}\)</span> to both sides.</li>
<li>We pick a vector <span class="math inline">\(v_i\)</span> such that the lower bound for that vector is less than the upper bound and pick a coefficient between those two bounds.</li>
</ol></li>
<li><p>We add <span class="math inline">\(X\)</span> with <span class="math inline">\(s \cdot v_i v_i\)</span> each step to get a large spherical matrix <span class="math inline">\(X^{(nd)}\)</span>.</p></li>
<li><p>Finally we multiply <span class="math inline">\(L_G^{1/2}\)</span> to both sides of <span class="math inline">\(X^{(nd)}\)</span> and do a rescale to obtain the Laplacian <span class="math inline">\(L_H\)</span>.</p></li>
</ol>
<p><strong>Complexity Analysis</strong> For analyzing the time complexity, we note that the reduction takes <span class="math inline">\(\mathcal{O}(n^3)\)</span> times to compute <span class="math inline">\(L^{+/2}\)</span> and <span class="math inline">\(\mathcal{O}(m \cdot n^2)\)</span> to compute <span class="math inline">\(v_i = \sqrt{w_i} L_G^{+/2} L_i\)</span>. Then, the algorithm takes <span class="math inline">\(\mathcal{O}(nd)\)</span> time to run the iterations and at each iteration upper bound and lower bound values should be computed for all vectors <span class="math inline">\(v_i\)</span>. To compute these upper and lower bounds, recall that in both <span class="math inline">\(\eqref{eq:upper-bound-potential}\)</span> and <span class="math inline">\(\eqref{eq:lower-bound-potential}\)</span> we need to compute the inverse of <span class="math inline">\(uI - A^{(i)}\)</span> and <span class="math inline">\(A^{(i)} - l I\)</span>. As a precompute step, we calculate both of them using <span class="math inline">\(\mathcal{O}(n^3)\)</span> algorithm and then compute every upper and lower bound by <span class="math inline">\(m \times \mathcal{O}(n^2)\)</span> operations for finding the quadratic form. Therefore, the total time complexity of the algorithm is <span class="math inline">\(\mathcal{O}(n^3 + m \cdot n^2 + nd \cdot m \cdot n^2) = \mathcal{O}(m n^3 d)\)</span>. Although the algorithm is not fast in particular, it is the first approach that gives near-linear edge counts. Other follow-up works have produced faster results with <span class="citation" data-cites="tat2015constructing">[@tat2015constructing]</span> giving an almost linear algorithm to find almost linear sparsifiers.</p>
</section>
<section id="experimental-details" class="level3">
<h3 class="anchored" data-anchor-id="experimental-details">Experimental Details</h3>
<p>We implemented the algorithm in Python and tested it on a set of graphs. Our package is available <a href="https://github.com/HamidrezaKmK/twice-ramanujan-sparsifiers">here</a> and <strong>?@fig-barbell</strong> demonstrates the results of the algorithm on a barbell graph.</p>
<!-- ```{python}
#| label: fig-barbell
#| fig-cap: "The Twice-Ramanujan sparsifier in action edges with more strength correspond to larger weights."
#| fig-subcap: 
#|  - "Checking the algorithm on a barbell graph."
#|  - "Checking the algorithm on a complete graph."

# preliminariy steps to include the package
import sys
import math
import networkx as nx
sys.path.append('..')

# importing the package
from src.TwiceRamanujan import TwiceRamanujan

# get the laplacian of a barbell graph
graphs = [nx.barbell_graph(5,0), nx.complete_graph(7)]
ds = [2, 3]

for g, d in zip(graphs, ds):
  
  # calculate epsilon according to d
  eps = 2 * math.sqrt(d) / (d + 1)

  # setup a twice-Ramanujan solver on the graph with d = 2
  tr = TwiceRamanujan(g, d=d, verbose=1)
  sparsified_laplacian = tr.sparsify()

  # draw both graphs
  tr.juxtapose()

  # verify
  tr.verify(eps=eps)
``` -->
<p>There were some subtleties in the implementation when numerical issues were encountered. For example, in the algorithm, we need to compute the inverse of <span class="math inline">\(uI - A^{(i)}\)</span> and <span class="math inline">\(A^{(i)} - l I\)</span> for the upper and lower bound values. This introduced a lot of accuracy issues, to circumvent this, we also implemented a binary search-based implementation to find the upper and lower bound for each vector <span class="math inline">\(v_i\)</span>; this turned out to be far superior although it impeded the runtime. You can simply trigger this mode by setting <code>fast=True</code> in the constructor of <code>TwiceRamanujan</code> class.</p>
</section>
</section>

</main>
<!-- /main column -->
<script id="quarto-html-after-body" type="application/javascript">
window.document.addEventListener("DOMContentLoaded", function (event) {
  const toggleBodyColorMode = (bsSheetEl) => {
    const mode = bsSheetEl.getAttribute("data-mode");
    const bodyEl = window.document.querySelector("body");
    if (mode === "dark") {
      bodyEl.classList.add("quarto-dark");
      bodyEl.classList.remove("quarto-light");
    } else {
      bodyEl.classList.add("quarto-light");
      bodyEl.classList.remove("quarto-dark");
    }
  }
  const toggleBodyColorPrimary = () => {
    const bsSheetEl = window.document.querySelector("link#quarto-bootstrap");
    if (bsSheetEl) {
      toggleBodyColorMode(bsSheetEl);
    }
  }
  toggleBodyColorPrimary();  
  const icon = "î§‹";
  const anchorJS = new window.AnchorJS();
  anchorJS.options = {
    placement: 'right',
    icon: icon
  };
  anchorJS.add('.anchored');
  const clipboard = new window.ClipboardJS('.code-copy-button', {
    target: function(trigger) {
      return trigger.previousElementSibling;
    }
  });
  clipboard.on('success', function(e) {
    // button target
    const button = e.trigger;
    // don't keep focus
    button.blur();
    // flash "checked"
    button.classList.add('code-copy-button-checked');
    var currentTitle = button.getAttribute("title");
    button.setAttribute("title", "Copied!");
    let tooltip;
    if (window.bootstrap) {
      button.setAttribute("data-bs-toggle", "tooltip");
      button.setAttribute("data-bs-placement", "left");
      button.setAttribute("data-bs-title", "Copied!");
      tooltip = new bootstrap.Tooltip(button, 
        { trigger: "manual", 
          customClass: "code-copy-button-tooltip",
          offset: [0, -8]});
      tooltip.show();    
    }
    setTimeout(function() {
      if (tooltip) {
        tooltip.hide();
        button.removeAttribute("data-bs-title");
        button.removeAttribute("data-bs-toggle");
        button.removeAttribute("data-bs-placement");
      }
      button.setAttribute("title", currentTitle);
      button.classList.remove('code-copy-button-checked');
    }, 1000);
    // clear code selection
    e.clearSelection();
  });
  function tippyHover(el, contentFn) {
    const config = {
      allowHTML: true,
      content: contentFn,
      maxWidth: 500,
      delay: 100,
      arrow: false,
      appendTo: function(el) {
          return el.parentElement;
      },
      interactive: true,
      interactiveBorder: 10,
      theme: 'quarto',
      placement: 'bottom-start'
    };
    window.tippy(el, config); 
  }
  const noterefs = window.document.querySelectorAll('a[role="doc-noteref"]');
  for (var i=0; i<noterefs.length; i++) {
    const ref = noterefs[i];
    tippyHover(ref, function() {
      // use id or data attribute instead here
      let href = ref.getAttribute('data-footnote-href') || ref.getAttribute('href');
      try { href = new URL(href).hash; } catch {}
      const id = href.replace(/^#\/?/, "");
      const note = window.document.getElementById(id);
      return note.innerHTML;
    });
  }
  const findCites = (el) => {
    const parentEl = el.parentElement;
    if (parentEl) {
      const cites = parentEl.dataset.cites;
      if (cites) {
        return {
          el,
          cites: cites.split(' ')
        };
      } else {
        return findCites(el.parentElement)
      }
    } else {
      return undefined;
    }
  };
  var bibliorefs = window.document.querySelectorAll('a[role="doc-biblioref"]');
  for (var i=0; i<bibliorefs.length; i++) {
    const ref = bibliorefs[i];
    const citeInfo = findCites(ref);
    if (citeInfo) {
      tippyHover(citeInfo.el, function() {
        var popup = window.document.createElement('div');
        citeInfo.cites.forEach(function(cite) {
          var citeDiv = window.document.createElement('div');
          citeDiv.classList.add('hanging-indent');
          citeDiv.classList.add('csl-entry');
          var biblioDiv = window.document.getElementById('ref-' + cite);
          if (biblioDiv) {
            citeDiv.innerHTML = biblioDiv.innerHTML;
          }
          popup.appendChild(citeDiv);
        });
        return popup.innerHTML;
      });
    }
  }
});
</script>
</div> <!-- /content -->



</body></html>