\section{Introduction}

Deep learning has achieved state-of-the-art performances across many applications such as image classification \citep{he2016deep} and language translation \citep{wu2016google}, in which the model is usually trained repeatedly on a large dataset from a stationary distribution. However, artificial general intelligence (AGI) should also have the ability to continually learn from a possibly time-varying environment with limited resources. Continual learning \citep{kirkpatrick2017overcoming} formulates this requirement by asking the model to learn from a series of tasks with varying distributions. The model is expected to quickly adapt to the new task without forgetting previous learnt abilities \citep{french1999catastrophic} .  

Regularization-based approaches in continual learning prevent the forgetting of previous abilities by adding regularization terms in the training loss. The regularization term usually forces the weight to stay close to the previous learnt weight, so that to avoid forgetting. Elastic Weight Consolidation (EWC) \citep{kirkpatrick2017overcoming} proposes to use quadratic distances to regularize how far the weight can move from the original weight, which motivates various importance criterions to quantify each individual weight \citep{zenke2017continual, aljundi2018memory, ritter2018online}. 
Besides regularizing the network using the weight-space metrics, another stream of approaches directly regularize the network over the functional outputs \citep{benjamin2018measuring, buzzega2020dark, rebuffi2017icarl}. Furthermore, continual learning is also associated to online posterior inference with stochastic predictors. Specifically, by using the KL divergence regularization, the learner evolves an online posterior along with new tasks.    For example, the variational continual learning (VCL) \citep{nguyen2017variational} updates the posterior of a Bayesian neural network to prevent from catastrophic forgetting.


In this paper I present a review and investigation of regularization-based approaches. Specifically, I find the regularizations lie either in the \emph{weight-space} or the \emph{function-space}, and I observe the utility of methods with \emph{deterministic} networks and \emph{stochastic} networks. In consequence, I categorie regularization-based approaches in continual learning. Furthermore, I study the connections within this umbrella and provide examplar demonstrations on how one can transform one approach to another one based on these connections. 
% Finally I briefly introduce other continual learning methods without using the regularization. 
In general, this paper provides a unified review for the regularization-based approaches, and provides potential directions to further solve the continual learning problem.